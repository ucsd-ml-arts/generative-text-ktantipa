{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a specification and model\n",
    "The following were the specification that I set before building and traning the model:\n",
    "\n",
    "Variable 'text' needs to be define first which is achieved from web_scraping.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "embedding_dim = 256 # The embedding dimension\n",
    "epochs = 50 \n",
    "seq_length = 200 # Sequence length\n",
    "vocab = sorted(set(text))\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "vocab_size = len(vocab) # Length of the vocabulary in chars\n",
    "rnn_units = 1024 # Number of RNN units\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples / targets\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "  rnn = tf.keras.layers.CuDNNGRU\n",
    "  rnn2 = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "  import functools\n",
    "  rnn = functools.partial(\n",
    "    tf.keras.layers.LSTM, recurrent_activation='sigmoid')  #Use LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing model\n",
    "\n",
    "To construct the model, I use embedding as my input layer. I added two LSTM layers as well as several dropouts. For the output layer, I use a dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "      \n",
    "    rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "      \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Dense(vocab_size)  \n",
    "    ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab), \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  #print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           15872     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (64, None, 256)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (64, None, 1024)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (64, None, 1024)          6297600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (64, None, 1024)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 62)            63550     \n",
      "=================================================================\n",
      "Total params: 10,315,326\n",
      "Trainable params: 10,315,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled_indices = tf.random.multinomial(example_batch_predictions[0], num_samples=1) # TF 1.12\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 200, 62)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.1274695\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training'\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 3s 325ms/step - loss: 4.5539\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 3.5561\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 3.1388\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 3.0059\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 2.8392\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 2s 195ms/step - loss: 2.6771\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 2.5254\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 2s 197ms/step - loss: 2.4021\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 2.3239\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 2s 197ms/step - loss: 2.2547\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 2s 199ms/step - loss: 2.1945\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 2.1388\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 2.0843\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 2.0332\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 1.9817\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 1.9332\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 2s 196ms/step - loss: 1.8863\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 1.8363\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 2s 200ms/step - loss: 1.7923\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 1.7484\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 1.7088\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 1.6599\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 1.6200\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 1.5806\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 1.5427\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 1.5022\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.4615\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.4256\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 1.3905\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.3610\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.3252\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 1.2952\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 1.2661\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 1.2371\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 1.2114\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 1.1777\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 2s 208ms/step - loss: 1.1580\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 1.1246\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 1.0948\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 1.0694\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 1.0446\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 1.0172\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 2s 205ms/step - loss: 0.9907\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 0.9675\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 2s 201ms/step - loss: 0.9414\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 0.9168\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 2s 204ms/step - loss: 0.8873\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 0.8611\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 2s 203ms/step - loss: 0.8364\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 2s 202ms/step - loss: 0.8091\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=50 # also try 70 epochs\n",
    "\n",
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training/ckpt_50'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            15872     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (1, None, 256)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (1, None, 1024)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_3 (CuDNNGRU)       (1, None, 1024)           6297600   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (1, None, 1024)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 62)             63550     \n",
      "=================================================================\n",
      "Total params: 10,315,326\n",
      "Trainable params: 10,315,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
